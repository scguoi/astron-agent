"""init

Revision ID: f2a4ce6e3198

Revises:
Create Date: 2026-02-11 18:01:05.510121

"""

from typing import Sequence, Union

import sqlalchemy as sa
import sqlmodel
from sqlalchemy.dialects import postgresql

from alembic import op  # type: ignore[attr-defined]

# revision identifiers, used by Alembic.
revision: str = "f2a4ce6e3198"
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "database_meta",
        sa.Column("id", sa.BigInteger(), nullable=False),
        sa.Column("uid", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("name", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("description", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("space_id", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("create_at", sa.DateTime(), nullable=False),
        sa.Column("update_at", sa.DateTime(), nullable=False),
        sa.Column("create_by", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("update_by", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.PrimaryKeyConstraint("id"),
        schema="sparkdb_manager",
    )
    op.create_index(
        op.f("ix_sparkdb_manager_database_meta_name"),
        "database_meta",
        ["name"],
        unique=False,
        schema="sparkdb_manager",
    )
    op.create_index(
        op.f("ix_sparkdb_manager_database_meta_space_id"),
        "database_meta",
        ["space_id"],
        unique=False,
        schema="sparkdb_manager",
    )
    op.create_index(
        op.f("ix_sparkdb_manager_database_meta_uid"),
        "database_meta",
        ["uid"],
        unique=False,
        schema="sparkdb_manager",
    )
    op.create_table(
        "schema_meta",
        sa.Column("id", sa.BigInteger(), nullable=False),
        sa.Column("database_id", sa.BigInteger(), nullable=False),
        sa.Column("schema_name", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("create_at", sa.DateTime(), nullable=False),
        sa.Column("update_at", sa.DateTime(), nullable=False),
        sa.Column("create_by", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("update_by", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.PrimaryKeyConstraint("id"),
        schema="sparkdb_manager",
    )
    op.create_index(
        op.f("ix_sparkdb_manager_schema_meta_schema_name"),
        "schema_meta",
        ["schema_name"],
        unique=False,
        schema="sparkdb_manager",
    )
    op.drop_table("database_name")
    op.drop_table("test_003")
    op.drop_table("book")
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "book",
        sa.Column(
            "id", sa.BIGINT(), autoincrement=True, nullable=False, comment="主键"
        ),
        sa.Column(
            "uuid", sa.VARCHAR(), autoincrement=False, nullable=False, comment="uuid"
        ),
        sa.Column(
            "create_time",
            postgresql.TIMESTAMP(),
            autoincrement=False,
            nullable=False,
            comment="创建时间",
        ),
        sa.Column(
            "user_name",
            sa.VARCHAR(),
            server_default=sa.text("' '::character varying"),
            autoincrement=False,
            nullable=False,
            comment="用户名称",
        ),
        sa.Column(
            "user_age",
            sa.INTEGER(),
            server_default=sa.text("0"),
            autoincrement=False,
            nullable=False,
            comment="用户年龄",
        ),
        sa.Column(
            "email",
            sa.VARCHAR(),
            autoincrement=False,
            nullable=True,
            comment="用户邮箱",
        ),
        sa.PrimaryKeyConstraint("id", name="book_pkey"),
        comment="测试使用表",
    )
    op.create_table(
        "test_003",
        sa.Column(
            "id", sa.BIGINT(), autoincrement=True, nullable=False, comment="主键id"
        ),
        sa.Column(
            "uid",
            sa.VARCHAR(length=36),
            autoincrement=False,
            nullable=False,
            comment="uid",
        ),
        sa.Column(
            "create_time",
            postgresql.TIMESTAMP(),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            autoincrement=False,
            nullable=False,
            comment="创建时间",
        ),
        sa.Column(
            "user_name",
            sa.VARCHAR(),
            autoincrement=False,
            nullable=False,
            comment="用户名称",
        ),
        sa.Column(
            "user_age",
            sa.INTEGER(),
            autoincrement=False,
            nullable=True,
            comment="用户的年龄",
        ),
        sa.Column(
            "user_email",
            sa.VARCHAR(),
            autoincrement=False,
            nullable=True,
            comment="用户邮箱",
        ),
        sa.Column(
            "dep_no",
            sa.INTEGER(),
            autoincrement=False,
            nullable=False,
            comment="部门信息",
        ),
        sa.PrimaryKeyConstraint("id", name="test_003_pkey"),
        comment="测试使用表",
    )
    op.create_table(
        "database_name",
        sa.Column("id", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column("app_id", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("uid", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column("name", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("description", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("schema", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column(
            "created_at", postgresql.TIMESTAMP(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "updated_at", postgresql.TIMESTAMP(), autoincrement=False, nullable=False
        ),
        sa.Column("created_by", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("updated_by", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.PrimaryKeyConstraint("id", name="database_name_pk"),
    )
    op.drop_index(
        op.f("ix_sparkdb_manager_schema_meta_schema_name"),
        table_name="schema_meta",
        schema="sparkdb_manager",
    )
    op.drop_table("schema_meta", schema="sparkdb_manager")
    op.drop_index(
        op.f("ix_sparkdb_manager_database_meta_uid"),
        table_name="database_meta",
        schema="sparkdb_manager",
    )
    op.drop_index(
        op.f("ix_sparkdb_manager_database_meta_space_id"),
        table_name="database_meta",
        schema="sparkdb_manager",
    )
    op.drop_index(
        op.f("ix_sparkdb_manager_database_meta_name"),
        table_name="database_meta",
        schema="sparkdb_manager",
    )
    op.drop_table("database_meta", schema="sparkdb_manager")
    # ### end Alembic commands ###
